{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# 测试GPU\n",
    "with tf.device('/device:GPU:0'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with allow_soft_placement and log_device_placement set\n",
    "# to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing accuracy 0.8931\n",
      "10.909832239151001\n",
      "Iter 1,Testing accuracy 0.9288\n",
      "21.274123907089233\n",
      "Iter 2,Testing accuracy 0.9482\n",
      "42.94618463516235\n",
      "Iter 3,Testing accuracy 0.9582\n",
      "51.13030457496643\n",
      "Iter 4,Testing accuracy 0.9649\n",
      "59.58170986175537\n",
      "Iter 5,Testing accuracy 0.9692\n",
      "69.34062027931213\n",
      "Iter 6,Testing accuracy 0.9723\n",
      "79.48051142692566\n",
      "Iter 7,Testing accuracy 0.9745\n",
      "91.17025876045227\n",
      "Iter 8,Testing accuracy 0.9762\n",
      "101.59339356422424\n",
      "Iter 9,Testing accuracy 0.9777\n",
      "111.7751727104187\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MINIST_data\",one_hot=True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "def variable_summary(var):\n",
    "    \"\"\"统计参数\"\"\"\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean',mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev',stddev)\n",
    "    tf.summary.scalar('max',tf.reduce_max(var))\n",
    "    tf.summary.scalar('min',tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram',var)\n",
    "\n",
    "#初始化权值\n",
    "def weight_variable(shape, name=None):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "#初始化偏置\n",
    "def bias_variable(shape, name=None):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "#卷积层\n",
    "def conv2d(x,w):\n",
    "    return tf.nn.conv2d(x,w,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "#池化层\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize = [1,2,2,1], strides = [1,2,2,1], padding='SAME')\n",
    "with tf.device('/device:GPU:0'):\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    with tf.name_scope('input'):\n",
    "        #placeholder\n",
    "        x = tf.placeholder(tf.float32,[None,784], name='x_input')\n",
    "        y = tf.placeholder(tf.float32,[None,10], name ='y_input')\n",
    "        \n",
    "        with tf.name_scope('x_image'):\n",
    "            #reshape for image\n",
    "            x_image = tf.reshape(x,[-1,28,28,1], name='x_image')\n",
    "\n",
    "    with tf.name_scope('Conv1'):\n",
    "        #初始化第一个卷积层\n",
    "        # 卷积大小（5x5）通道（1）输出层\n",
    "        with tf.name_scope('w_conv1'):\n",
    "            w_conv1 = weight_variable([5,5,1,8], name='w_conv1')\n",
    "        with tf.name_scope('b_conv1'):\n",
    "            b_conv1 = bias_variable([8], name='b_conv1')\n",
    "\n",
    "        #卷积及池化操作\n",
    "        with tf.name_scope('conv2d_1'):\n",
    "            conv2d_1 = conv2d(x_image,w_conv1) + b_conv1\n",
    "            \n",
    "        with tf.name_scope('relu'):\n",
    "            h_conv1 = tf.nn.relu(conv2d_1)\n",
    "        with tf.name_scope('h_pool1'):\n",
    "            h_pool1 = max_pool_2x2(h_conv1) # 14x14x32\n",
    "\n",
    "    #第二个卷积层\n",
    "    with tf.name_scope('Conv2'):\n",
    "        with tf.name_scope('w_conv2'):\n",
    "            w_conv2 = weight_variable([5,5,8,20], name='w_conv2')\n",
    "        with tf.name_scope('b_conv2'):\n",
    "            b_conv2 = bias_variable([20], name='b_conv2')\n",
    "\n",
    "        #卷积及池化操作\n",
    "        with tf.name_scope('conv2d_2'):\n",
    "            conv2d_2 = conv2d(h_pool1,w_conv2) + b_conv2\n",
    "        with tf.name_scope('relu'):\n",
    "            h_conv2 = tf.nn.relu(conv2d_2)\n",
    "        with tf.name_scope('h_pool2'):\n",
    "            h_pool2 = max_pool_2x2(h_conv2) # 7x7*64\n",
    "\n",
    "    #两层处理后 结果为 7x7大小\n",
    "\n",
    "    #初始化第一个全连接层的权值\n",
    "    with tf.name_scope('fc1'):\n",
    "        with tf.name_scope('w_fc1'):\n",
    "            w_fc1 = weight_variable([7*7*20,500], name='w_fc1')\n",
    "        with tf.name_scope('b_fc1'):\n",
    "            b_fc1 = bias_variable([500], name='b_fc1')\n",
    "\n",
    "    with tf.name_scope('h_pool2_flat'):\n",
    "        h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*20], name='h_pool2_flat')\n",
    "    with tf.name_scope('wx_plub_b1'):\n",
    "        wx_plub_b1 = tf.matmul(h_pool2_flat,w_fc1) + b_fc1\n",
    "    with tf.name_scope('relu'):\n",
    "        h_fc1 = tf.nn.relu(wx_plub_b1)\n",
    "    \n",
    "    # 神经元的输出概率\n",
    "    with tf.name_scope('keep_prob'):\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    with tf.name_scope('h_fc1_drop'):\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob, name='h_fc1_drop')\n",
    "\n",
    "    #初始化第二个全连接层\n",
    "    with tf.name_scope('fc2'):\n",
    "        with tf.name_scope('w_fc2'):\n",
    "            w_fc2 = weight_variable([500,10], name='w_fc2')\n",
    "        with tf.name_scope('b_fc2'):\n",
    "            b_fc2 = bias_variable([10], name='b_fc2')\n",
    "        with tf.name_scope('wx_plus_b2'):\n",
    "            wx_plus_b2 = tf.matmul(h_fc1_drop,w_fc2) + b_fc2\n",
    "        with tf.name_scope('softmax'):\n",
    "            prediction = tf.nn.softmax(wx_plus_b2)\n",
    "\n",
    "    #交叉熵代价函数\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y,logits = prediction), name='cross_entropy')\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "    #优化器\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    \n",
    "    # 准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32), name='accuracy')\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "start = time.time()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement=True\n",
    "config.allow_soft_placement = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer = tf.summary.FileWriter('logs/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter('logs/test', sess.graph)\n",
    "    for epoch in range(10):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "           \n",
    "            # summary = sess.run(merged, feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "            # train_writer.add_summary(summary, epoch)\n",
    "            \n",
    "            # 测试集\n",
    "            # batch_xs,batch_ys = mnist.test.next_batch(batch_size)\n",
    "            # summary = sess.run(merged, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.0})\n",
    "            # test_writer.add_summary(summary, epoch)\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels,keep_prob:0.7})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing accuracy \" + str(acc))\n",
    "        print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.gpu_options."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
